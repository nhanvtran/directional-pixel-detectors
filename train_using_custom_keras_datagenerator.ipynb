{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from typing import Union, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, \n",
    "                data_directory_path: str = \"./\",\n",
    "                labels_directory_path: str = \"./\",\n",
    "                is_directory_recursive: bool = False,\n",
    "                file_type: str = \"*csv\",\n",
    "                data_format: str = \"2D\",\n",
    "                batch_size: int = 32,\n",
    "                file_count = None,\n",
    "                labels_list: Union[List,str] = \"cotAlpha\",\n",
    "                to_standardize: bool = False,\n",
    "                input_shape: Tuple = (13,21),\n",
    "                include_y_local:bool = False,\n",
    "                **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Data Generator to streamline data input to the network direct from the directory.\n",
    "        Args:\n",
    "        data_directory_path:\n",
    "        labels_directory_path: \n",
    "        is_directory_recursive: \n",
    "        file_type: Default: \"*.csv\"\n",
    "                   Adapt the data loader according to file type. For now, it only supports .csv file format.\n",
    "        data_format: Default: 2D\n",
    "                     Used to refer to the relevant \"recon\" files, 2D for 2D pixel array, 3D for time series input,\n",
    "        batch_size: Default: 32\n",
    "                    The no. of data points to be included in a single batch.\n",
    "        file_count: Default: None\n",
    "                    To limit the no. of .csv files to be used for training.\n",
    "                    If set to None, all files will be considered as legitimate inputs.\n",
    "        labels_list: Default: \"cotAlpha\"\n",
    "                     Input column name or list of column names to be used as label input to the neural network.\n",
    "        to_standardize: If set to True, it ensures that batches are normalized prior to being used as inputs\n",
    "                        for training.\n",
    "                        Default: False\n",
    "        input_shape: Default: (13,21) for image input to a 2D feedforward neural network.\n",
    "                    To reshape the input array per the requirements of the network training.\n",
    "        \"\"\"\n",
    "        self.recon_files = glob.glob(data_directory_path + \"recon\" + data_format + file_type, \n",
    "                                    recursive=is_directory_recursive)\n",
    "        \n",
    "        self.recon_files.sort()\n",
    "        print(len(self.recon_files))\n",
    "        self.label_files = glob.glob(labels_directory_path + \"labels\" + file_type, \n",
    "                                     recursive=is_directory_recursive)\n",
    "        self.label_files.sort()\n",
    "        \n",
    "        if file_count != None:\n",
    "            self.recon_files = self.recon_files[:file_count]\n",
    "            self.label_files = self.label_files[:file_count]\n",
    "            \n",
    "        self.batch_size = batch_size\n",
    "        self.labels_list = labels_list\n",
    "        self.input_shape = input_shape\n",
    "        self.to_standardize = to_standardize\n",
    "        self.include_y_local = include_y_local\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    \n",
    "    def standardize(self, x):\n",
    "        \"\"\"Applies the normalization configuration in-place to a batch of\n",
    "        inputs.\n",
    "        `x` is changed in-place since the function is mainly used internally\n",
    "        to standardize images and feed them to your network.\n",
    "        Args:\n",
    "            x: Batch of inputs to be normalized.\n",
    "        Returns:\n",
    "            The inputs, normalized. \n",
    "        \"\"\"\n",
    "        x -= np.mean(x, keepdims=True)   \n",
    "        x /= np.std(x, keepdims=True) + 1e-10\n",
    "        return x\n",
    "        \n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Inherited from the parent class.\n",
    "        Used to reset indices but not of significance in this datagenerator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Used to fetch a batch of inputs (X,y) for the network's training.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_index = random.randrange(0,len(self.recon_files))\n",
    "        recon_df = pd.read_csv(self.recon_files[file_index])\n",
    "        labels_df = pd.read_csv(self.label_files[file_index])\n",
    "        \n",
    "        chosen_idxs = random.sample([i for i in range(0,len(labels_df))], self.batch_size)\n",
    "        \n",
    "        X = recon_df.iloc[chosen_idxs].values\n",
    "        if len(self.input_shape) == 1:\n",
    "            X = X.reshape(self.batch_size,self.input_shape[0])\n",
    "        if len(self.input_shape) == 2:\n",
    "            X = X.reshape(self.batch_size,self.input_shape[0],self.input_shape[1])\n",
    "        elif len(self.input_shape) == 3:\n",
    "            X = X.reshape(self.batch_size,self.input_shape[0],self.input_shape[1],\n",
    "                          self.input_shape[2])\n",
    "        elif len(self.input_shape) == 4:\n",
    "            X = X.reshape(self.batch_size, self.input_shape[0], self.input_shape[1], \n",
    "                          self.input_shape[2], self.input_shape[3])\n",
    "            \n",
    "        y = labels_df.iloc[chosen_idxs][self.labels_list].values\n",
    "        if self.to_standardize:\n",
    "            X = self.standardize(X)\n",
    "        if self.include_y_local:\n",
    "            y_local = labels_df.iloc[chosen_idxs][\"y-local\"].values\n",
    "            return [X, y_local], y\n",
    "        else:\n",
    "            return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for f in self.label_files:\n",
    "            x = pd.read_csv(f)\n",
    "            count += x.shape[0]\n",
    "        return count // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_directory_path = \"./data/raw/\"\n",
    "# file_type = \"*.csv\"\n",
    "# data_format = \"2D\"\n",
    "# batch_size = 1000\n",
    "# labels_list = [\"cotAlpha\", \"cotBeta\"]\n",
    "# image_shape = (13,21)\n",
    "# recon_files = glob.glob(data_directory_path + \"recon\" + data_format + file_type, recursive=True)\n",
    "# recon_files.sort()\n",
    "# label_files = glob.glob(data_directory_path + \"labels\" + file_type, recursive=True)\n",
    "# label_files.sort()\n",
    "\n",
    "# # part \n",
    "# # chose a file's index at random and load the csvs corresponding to that index\n",
    "# index = random.randrange(0,len(recon_files))\n",
    "# recon_df = pd.read_csv(recon_files[index])\n",
    "# labels_df = pd.read_csv(label_files[index])\n",
    "# chosen_idxs = random.sample([i for i in range(0,len(labels_df))], batch_size)\n",
    "# X = recon_df.iloc[chosen_idxs].values.reshape(batch_size,image_shape[0], image_shape[1])\n",
    "# y = labels_df.iloc[chosen_idxs][labels_list].values\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (BatchNormalization, Flatten, Input, Reshape, Dense, MaxPool2D,\n",
    "                          Conv1D, MaxPool1D, Conv2D, Dropout, Conv3D, concatenate)\n",
    "\n",
    "class RegModelCotBeta3D:\n",
    "    def build_image_branch(self,inputs):\n",
    "#     def build_image_branch(self,inputs,y_local):\n",
    "        x = Conv2D(64, (2, 2), kernel_initializer = \"he_normal\",\n",
    "                   strides=(2, 2), activation='relu',\n",
    "                   data_format = \"channels_first\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(32, (2, 2), kernel_initializer = \"he_normal\",\n",
    "                   strides=(2, 2), activation='relu',\n",
    "                   data_format = \"channels_first\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate = 0.15)(x)\n",
    "        x = Flatten()(x)\n",
    "#         x = concatenate([x,y_local])\n",
    "        x = Dense(32, kernel_initializer = \"he_normal\", activation='relu', use_bias = False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(16, kernel_initializer = \"he_normal\", activation='relu', use_bias = False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(1, activation= \"linear\", name = \"final_output\")(x)\n",
    "\n",
    "        return x\n",
    " \n",
    "    def assemble_model(self):\n",
    "        inputs = Input ( shape = (10,13,21) )\n",
    "        y_local = Input(shape = (1,))\n",
    "#         outputs = self.build_image_branch(inputs,y_local)\n",
    "        outputs = self.build_image_branch(inputs)\n",
    "        model = Model(inputs =[inputs], outputs=outputs, name = \"cotBeta_3D_model\")\n",
    "#         model = Model(inputs =[inputs,y_local], outputs=outputs, name = \"cotBeta_3D_model\")\n",
    "        print( model.summary() )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y, p):\n",
    "    \n",
    "    maxval = 1e6\n",
    "    minval = 1e-9\n",
    "    pi = 3.14159265359\n",
    "    \n",
    "    mu = tf.reduce_mean(p, axis=1)\n",
    "    sigma = tf.clip_by_value(tf.reduce_mean(p, axis=1),minval,maxval)\n",
    "        \n",
    "    term = tf.clip_by_value(1.0/tf.math.sqrt(2*pi)/sigma*tf.math.exp(-1*(y-mu)*(y-mu)/(2*sigma*sigma)),minval,maxval)\n",
    "    NLL = tf.clip_by_value(-1*tf.math.log(term),minval,maxval)\n",
    "    \n",
    "    return tf.keras.backend.sum(NLL,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb52914",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.now ( )\n",
    "epochs = 5\n",
    "batch_size = 7500\n",
    "val_batch_size = 7500\n",
    "use_file_size = None\n",
    "training_generator = CustomDataGenerator(\n",
    "                                        data_directory_path = \"./data/processed/3D-10TS/\",\n",
    "                                        labels_directory_path = \"./data/raw/labels/\",\n",
    "                                        is_directory_recursive = False,\n",
    "                                        file_type = \"*csv\",\n",
    "                                        data_format = \"3D\",\n",
    "                                        batch_size = batch_size,\n",
    "                                        file_count = use_file_size,\n",
    "                                        to_standardize= True,\n",
    "                                        include_y_local= False,\n",
    "                                        labels_list = \"cotBeta\",\n",
    "                                        input_shape = (10,13,21))\n",
    "\n",
    "validation_generator = CustomDataGenerator(\n",
    "                                        data_directory_path = \"./data/processed/3D-10TS/\",\n",
    "                                        labels_directory_path = \"./data/raw/labels/\",\n",
    "                                        is_directory_recursive = False,\n",
    "                                        file_type = \"*csv\",\n",
    "                                        data_format = \"3D\",\n",
    "                                        batch_size = val_batch_size,\n",
    "                                        file_count = 25,\n",
    "                                        to_standardize= True,\n",
    "                                        include_y_local= False,\n",
    "                                        labels_list = \"cotBeta\",\n",
    "                                        input_shape = (10,13,21))\n",
    "\n",
    "model = RegModelCotBeta3D().assemble_model()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Nadam(lr = 2.75e-3), \n",
    "              loss = custom_loss)\n",
    "\n",
    "history = model.fit(x=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=epochs,\n",
    "                    verbose = True)\n",
    "\n",
    "end_date = datetime.datetime.now ( )\n",
    "print ( \"Total Training Time = {}\".format (end_date - start_date ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90133ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], color = \"blue\",marker = \"x\")\n",
    "plt.plot(history.history[\"val_loss\"], color =\"red\", marker = \".\")\n",
    "# plt.xticks([0,1,2,3,4,5,6,7,8,9,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e152a41",
   "metadata": {},
   "source": [
    "### Test Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312bbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon = pd.read_csv(\"./data/test/recon3D10_test.csv\")\n",
    "test_labels_df = pd.read_csv(\"./data/test/labels_test.csv\")\n",
    "test_labels = test_labels_df[\"cotBeta\"]\n",
    "test_y_local = test_labels_df[\"y-local\"]\n",
    "print(test_recon.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = test_recon.values.reshape(test_recon.shape[0],10,13,21)\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Applies the normalization configuration in-place to a batch of\n",
    "    inputs.\n",
    "    `x` is changed in-place since the function is mainly used internally\n",
    "    to standardize images and feed them to your network.\n",
    "    Args:\n",
    "        x: Batch of inputs to be normalized.\n",
    "    Returns:\n",
    "        The inputs, normalized. \n",
    "    \"\"\"\n",
    "    x -= np.mean(x, keepdims=True)   \n",
    "    x /= np.std(x, keepdims=True) + 1e-10\n",
    "    return x\n",
    "\n",
    "test_inputs = standardize(test_inputs)\n",
    "\n",
    "cotBeta_predictions = model.predict(test_inputs, batch_size = 1000)\n",
    "# cotBeta_predictions = model.predict([test_inputs,test_y_local.values], batch_size = 1000)\n",
    "df = pd.DataFrame(cotBeta_predictions[:,0], columns = [\"preds\"])\n",
    "df[\"truth\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d021186",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,5), dpi = 80)\n",
    "plt.hist(df[\"truth\"], bins = 100, color = \"darkblue\", alpha = 0.5, )\n",
    "plt.hist(df[\"preds\"], bins = 100, color = \"red\", alpha = 0.3)\n",
    "# plt.xlim([-10,10])\n",
    "# plt.xticks([i for i in range(10, -11, -2)])\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"cotBeta\")\n",
    "plt.legend([\"truth\", \"preds\"])\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', alpha=0.5,color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a85d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_profile(x, y, nbin=100):\n",
    "    \n",
    "    # use of the 2d hist by numpy to avoid plotting\n",
    "    h, xe, ye = np.histogram2d(x,y,nbin)\n",
    "    \n",
    "    # bin width\n",
    "    xbinw = xe[1]-xe[0]\n",
    "\n",
    "    # getting the mean and RMS values of each vertical slice of the 2D distribution\n",
    "    # also the x valuse should be recomputed because of the possibility of empty slices\n",
    "    x_array      = []\n",
    "    x_slice_mean = []\n",
    "    x_slice_rms  = []\n",
    "    for i in range(xe.size-1):\n",
    "        yvals = y[ (x>xe[i]) & (x<=xe[i+1]) ]\n",
    "        if yvals.size>0: # do not fill the quanties for empty slices\n",
    "            x_array.append(xe[i]+ xbinw/2)\n",
    "            x_slice_mean.append( yvals.mean())\n",
    "            x_slice_rms.append( yvals.std())\n",
    "    x_array = np.array(x_array)\n",
    "    x_slice_mean = np.array(x_slice_mean)\n",
    "    x_slice_rms = np.array(x_slice_rms)\n",
    "\n",
    "    return x_array, x_slice_mean, x_slice_rms\n",
    "\n",
    "plt.figure(figsize = (7,4), dpi= 90)\n",
    "p_x, p_mean, p_rms = compute_profile(x = df[\"truth\"],\n",
    "                                     y = df[\"truth\"] - df[\"preds\"],\n",
    "                                     nbin = 50)\n",
    "plt.errorbar(p_x, p_mean, p_rms,fmt='_', ecolor='blue', color='blue')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Truth\")\n",
    "plt.ylabel(\"cotBeta Residuals\")\n",
    "# plt.ylim([-0.5,0.5])\n",
    "# plt.xlim([-0.6,0.6])\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', alpha=0.5,color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = df[\"truth\"] - df[\"preds\"]\n",
    "print(np.mean(residuals), np.std(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./models/keras_cnn_cotBeta_3d_20TS.h5\")\n",
    "# model = keras.models.load_model(\"./models/keras_cnn_cotBeta_3d_05TS.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec455ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
